{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anindyabecs/neural_network_diagrams/blob/main/Apollo_Dashboard.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import random\n",
        "from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode\n",
        "\n",
        "# 1. Page Configuration\n",
        "st.set_page_config(\n",
        "    page_title=\"Apollo Dashboard\",\n",
        "    page_icon=\"üöÄ\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# 2. Custom CSS for Styling\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    /* Center text in metrics */\n",
        "    [data-testid=\"stMetric\"] {\n",
        "        width: fit-content;\n",
        "        margin: auto;\n",
        "    }\n",
        "    [data-testid=\"stMetricValue\"] {\n",
        "        text-align: center;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    [data-testid=\"stMetricLabel\"] {\n",
        "        text-align: center;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    /* Custom styling for the Table */\n",
        "    .stDataFrame {\n",
        "        width: 100%;\n",
        "    }\n",
        "    </style>\n",
        "\"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "# 3. Mock Data Generator (Updated with new Columns)\n",
        "@st.cache_data\n",
        "def get_apollo_data():\n",
        "    data = []\n",
        "    statuses = [\"Active\", \"Draft\", \"Deprecated\", \"Review\"]\n",
        "    sources = [\"CRM DB\", \"Web Events\", \"IoT Gateway\", \"Legacy Mainframe\", \"Partner API\"]\n",
        "    # Types that map to the requested Transport Mediums\n",
        "    types = [\"JSON\", \"Avro\", \"Parquet\", \"XML\", \"CSV\"]\n",
        "    downstreams = [\"Data Lake\", \"Fraud Engine\", \"Marketing Analytics\", \"Billing System\"]\n",
        "    processing_systems = [\"Apollo Core\", \"Spark Cluster\", \"AWS Lambda\", \"Flink Stream\"]\n",
        "    transport_types_technical = [\"SFTP\", \"HTTPS\", \"JMS\", \"S3 Bucket\", \"Kafka Topic\"]\n",
        "    delimiters = [\",\", \"|\", \";\", \"\\\\t\", \"Fixed Width\"]\n",
        "\n",
        "    # Database options\n",
        "    db_types = [\"Oracle 19c\", \"PostgreSQL 14\", \"MS SQL Server\", \"MongoDB\", \"Snowflake\"]\n",
        "    db_names = [\"APOLLO_CORE\", \"CUST_DATA_LGR\", \"TRANS_HIST_V2\", \"REF_MASTER\", \"STAGING_DB\"]\n",
        "\n",
        "    # Generate 30 sample specs\n",
        "    for i in range(1, 31):\n",
        "        spec_name = f\"Apollo_Spec_{chr(65 + (i%26))}_Ingest_{i}\"\n",
        "        source = random.choice(sources)\n",
        "        dtype = random.choice(types)\n",
        "\n",
        "        # Logic for file-specific fields\n",
        "        is_file = dtype in [\"CSV\", \"XML\", \"JSON\", \"Parquet\"]\n",
        "\n",
        "        # Logic for \"Transport Medium\" (XML, CSV, DB) request\n",
        "        transport_medium = \"N/A\"\n",
        "        current_db_type = \"N/A\"\n",
        "        current_db_name = \"N/A\"\n",
        "\n",
        "        if dtype == \"XML\":\n",
        "            transport_medium = \"XML\"\n",
        "        elif dtype == \"CSV\":\n",
        "            transport_medium = \"CSV\"\n",
        "        elif \"DB\" in source or \"Mainframe\" in source:\n",
        "            transport_medium = \"DB\"\n",
        "            current_db_type = random.choice(db_types)\n",
        "            current_db_name = random.choice(db_names)\n",
        "        else:\n",
        "            # Fallback for others to match request roughly or assign random\n",
        "            transport_medium = random.choice([\"DB\", \"XML\", \"CSV\"])\n",
        "            if transport_medium == \"DB\":\n",
        "                 current_db_type = random.choice(db_types)\n",
        "                 current_db_name = random.choice(db_names)\n",
        "\n",
        "        data.append({\n",
        "            \"Data Spec Name\": spec_name,\n",
        "            \"Data Spec Description\": f\"Ingests {dtype} data from {source} for {random.choice(downstreams)}.\",\n",
        "            \"Source\": source,\n",
        "            \"Type\": dtype,\n",
        "            \"Downstream\": random.choice(downstreams),\n",
        "            \"Processing System\": random.choice(processing_systems),\n",
        "            \"Service Endpoint\": f\"https://api.apollo.internal/v1/ingest/{1000 + i}\",\n",
        "\n",
        "            # Requested Details Pane Fields\n",
        "            \"Transport Medium\": transport_medium,\n",
        "            \"Database Type\": current_db_type,\n",
        "            \"Database Name\": current_db_name,\n",
        "\n",
        "            # Existing Columns\n",
        "            \"Transport Type\": random.choice(transport_types_technical),\n",
        "            \"XML Path\": f\"/root/payload/data/v{i}\" if transport_medium == \"XML\" else \"N/A\",\n",
        "            \"File Path\": f\"/mnt/apollo/landing/{spec_name.lower()}/\" if is_file else \"N/A\",\n",
        "            \"File Name\": f\"batch_input_{1000+i}.{dtype.lower()}\" if is_file else \"N/A\",\n",
        "            \"File Delimiter\": random.choice(delimiters) if transport_medium == \"CSV\" else \"N/A\",\n",
        "\n",
        "            # Keeping these for KPIs and Charts logic\n",
        "            \"Status\": random.choice(statuses),\n",
        "            \"Rules Associated\": random.randint(5, 65),\n",
        "            \"Spec ID\": f\"SPC-{1000 + i}\"\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Load data\n",
        "df = get_apollo_data()\n",
        "\n",
        "# --- HEADER SECTION ---\n",
        "col_logo, col_title, col_btn = st.columns([1, 10, 2])\n",
        "\n",
        "with col_logo:\n",
        "    # Big Rocket Logo\n",
        "    st.markdown(\"## üöÄ\")\n",
        "\n",
        "with col_title:\n",
        "    st.title(\"Apollo Application Monitor\")\n",
        "    st.write(\"Real-time oversight of Service Endpoints, Data Specs, and Rules.\")\n",
        "\n",
        "with col_btn:\n",
        "    if st.button(\"Refresh Data\", type=\"primary\", icon=\":material/refresh:\"):\n",
        "        st.rerun()\n",
        "\n",
        "# --- KPI SECTION ---\n",
        "with st.container():\n",
        "    kpi1, kpi2, kpi3 = st.columns(3)\n",
        "\n",
        "    # KPI 1: Service Endpoint (Count)\n",
        "    with kpi1:\n",
        "        with st.container(border=True):\n",
        "            st.metric(\n",
        "                label=\"Service Endpoints\",\n",
        "                value=len(df), # Dynamic count based on rows\n",
        "                help=\"Total active service endpoints.\"\n",
        "            )\n",
        "\n",
        "    # KPI 2: Data Specs\n",
        "    with kpi2:\n",
        "        with st.container(border=True):\n",
        "            active_specs = len(df[df['Status'] == 'Active'])\n",
        "            st.metric(\n",
        "                label=\"Data Specs\",\n",
        "                value=len(df),\n",
        "                help=\"The data flow between systems.\"\n",
        "            )\n",
        "\n",
        "    # KPI 3: Total Rules\n",
        "    with kpi3:\n",
        "        with st.container(border=True):\n",
        "            total_rules = df[\"Rules Associated\"].sum()\n",
        "            st.metric(\n",
        "                label=\"Total Rules\",\n",
        "                value=total_rules,\n",
        "                help=\"The total number of explicit rules set for the application.\"\n",
        "            )\n",
        "\n",
        "# --- FILTERS & DATA TABLE ---\n",
        "st.subheader(\"üìã Data Specification Details\")\n",
        "\n",
        "# Filter Layout\n",
        "f1, f2, f3 = st.columns([2, 2, 2])\n",
        "with f1:\n",
        "    search_query = st.text_input(\"Search Data Spec Name\", placeholder=\"Type to search (e.g., Spec_C)...\")\n",
        "with f2:\n",
        "    status_filter = st.multiselect(\"Filter by Status\", df[\"Status\"].unique(), default=[\"Active\", \"Draft\"])\n",
        "\n",
        "# Column Selection Logic (Visible in Grid)\n",
        "all_columns_display = [\n",
        "    \"Data Spec Name\", \"Data Spec Description\", \"Source\", \"Type\",\n",
        "    \"Downstream\", \"Processing System\", \"Service Endpoint\", \"Status\",\n",
        "    \"Transport Medium\", \"Database Type\"\n",
        "]\n",
        "default_columns = [\n",
        "    \"Data Spec Name\", \"Data Spec Description\", \"Source\", \"Type\",\n",
        "    \"Downstream\", \"Processing System\", \"Service Endpoint\", \"Status\"\n",
        "]\n",
        "\n",
        "with f3:\n",
        "    selected_columns = st.multiselect(\n",
        "        \"Customize Table Columns\",\n",
        "        options=all_columns_display,\n",
        "        default=default_columns,\n",
        "        placeholder=\"Add/Remove columns...\"\n",
        "    )\n",
        "\n",
        "# Apply Filters\n",
        "filtered_df = df.copy()\n",
        "if status_filter:\n",
        "    filtered_df = filtered_df[filtered_df[\"Status\"].isin(status_filter)]\n",
        "if search_query:\n",
        "    filtered_df = filtered_df[filtered_df[\"Data Spec Name\"].str.contains(search_query, case=False)]\n",
        "\n",
        "# --- MAIN LAYOUT (GRID) ---\n",
        "with st.container(border=True):\n",
        "    # Configure AgGrid\n",
        "    gb = GridOptionsBuilder.from_dataframe(filtered_df)\n",
        "\n",
        "    # Configure Selection to be Single Row (Clicking a row triggers selection)\n",
        "    gb.configure_selection('single', use_checkbox=False)\n",
        "\n",
        "    # Pagination Settings\n",
        "    gb.configure_pagination(paginationAutoPageSize=False, paginationPageSize=10)\n",
        "\n",
        "    # Hiding columns that aren't selected in the multiselect,\n",
        "    # BUT keeping them in the dataframe so the Details Pane can access them.\n",
        "    for col in filtered_df.columns:\n",
        "        if col not in selected_columns:\n",
        "            gb.configure_column(col, hide=True)\n",
        "        else:\n",
        "            gb.configure_column(col, hide=False)\n",
        "\n",
        "    gb.configure_side_bar()\n",
        "    gridOptions = gb.build()\n",
        "\n",
        "    # Display Grid\n",
        "    grid_response = AgGrid(\n",
        "        filtered_df,\n",
        "        gridOptions=gridOptions,\n",
        "        enable_enterprise_modules=False,\n",
        "        height=500,\n",
        "        theme='streamlit',\n",
        "        update_mode=GridUpdateMode.SELECTION_CHANGED,\n",
        "        data_return_mode=DataReturnMode.FILTERED_AND_SORTED\n",
        "    )\n",
        "\n",
        "# --- POPUP DIALOG LOGIC ---\n",
        "\n",
        "@st.dialog(\"üîç Service Endpoint Details\")\n",
        "def show_endpoint_details(row):\n",
        "    # Use native Streamlit components instead of HTML to prevent rendering issues\n",
        "    st.caption(\"Service Endpoint Name\")\n",
        "    st.code(row.get('Service Endpoint', 'N/A'), language=None)\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    st.markdown(\"##### üì¶ Transport Configuration\")\n",
        "    t_col1, t_col2 = st.columns(2)\n",
        "    with t_col1:\n",
        "        st.markdown(\"**Medium**\")\n",
        "        st.info(row.get('Transport Medium', 'N/A'))\n",
        "        st.markdown(\"**File Type**\")\n",
        "        st.write(row.get('Type', 'N/A'))\n",
        "    with t_col2:\n",
        "        st.markdown(\"**File Name**\")\n",
        "        st.write(row.get('File Name', 'N/A'))\n",
        "        st.markdown(\"**Delimiter**\")\n",
        "        st.code(row.get('File Delimiter', 'N/A'))\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    st.markdown(\"##### üóÑÔ∏è Database Info\")\n",
        "    d_col1, d_col2 = st.columns(2)\n",
        "    with d_col1:\n",
        "        st.markdown(\"**DB Type**\")\n",
        "        st.write(row.get('Database Type', 'N/A'))\n",
        "    with d_col2:\n",
        "        st.markdown(\"**DB Name**\")\n",
        "        st.write(row.get('Database Name', 'N/A'))\n",
        "\n",
        "    st.divider"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'streamlit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2668205231.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstreamlit\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpress\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mst_aggrid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgGrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridOptionsBuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGridUpdateMode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataReturnMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'streamlit'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "execution_count": null,
      "metadata": {
        "id": "SEMplIDDMnY3",
        "outputId": "cfcbe4b3-ea3d-4da6-9157-8aa20b53cd2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        }
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}